{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on notations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout the introduction chapter, number of data points is used as a number of features (or dimensionality) of dataset.<br>\n",
    "> **Number of point = number of features = columns number = n**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a single data point (feature) only, the neural network takes one data point at a time and outputs a single prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = 0.1 # initialize weight (usually random or zeros)\n",
    "\n",
    "def neural_network(input_datapoint, weight):\n",
    "    predictions = input_datapoint * weight\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network inputs the input data, multiplies it by *knowledge* (weight) and outputs *predictions*.<br>\n",
    "Apply this function to an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_toes = [8.5, 9.5, 10, 9] # number of toes - feature. len(number_of_toes) - m = dataset size (number of samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8500000000000001"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network(number_of_toes[0], weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's activate all weights and check the dimensions of input, weights and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize 4 weighs randomly\n",
    "weights = 0.1\n",
    "number_of_toes = np.array([8.5, 9.5, 10, 9]).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the input data (1, 4)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of the input data', number_of_toes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_activ =  weights * number_of_toes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85, 0.95, 1.  , 0.9 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_activ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the linear activation (1, 4)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of the linear activation', linear_activ.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, applying knowledge (weights), we activate all samples (m). <br>\n",
    "Note that in this case the `hidden_dim = 1`.<br>\n",
    "**Important**: one weight for one feature! **Dimension of weights has nothing with the batch size m**, it has a shape of (*input_dim*, *hidden_dim*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's worth mentioning that in aove case we used batch (m) = 4 with a single feature and only 1 hiddden neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Important note**: NN does not have an access to information except one instance!<br>\n",
    " I.e. when we feed the input data of batch m (for example, a single data sample of m = 1), net does not remember predictions from last timestamps. It does not have access to previous instances.<br>\n",
    " Later on, it's solved by RNN and LSTMs in particular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight as a measure of sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of the weights as a measure of sensitivity between the input data and predictions.<br>\n",
    "If the **weight is very high**, then even the **tiniest input will create a large prediction**.<br>\n",
    "Thant's why we pay attention to regularisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last note: neural network can both input and output **either negative or positive values**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions with multiple inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks can combine predictions from **multiple inputs**. <br>\n",
    "Along with the average number of toes, we can provide other features (other input data) - **win loss** and **number of fans**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [0.1, 0.2, 0.3] # three weights for 3 features\n",
    "def neural_network(inputs, weights):\n",
    "    # apply \"weighted sum\" function that we will define below\n",
    "    pred = w_sum(inputs, weights)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "toes = [8.5, 9.5, 9.9, 9.0] # average number of toes\n",
    "wlrec = [0.65, 0.8, 0.8, 0.9] # win loss\n",
    "nfans = [1.2, 1.3, 0.5, 1.0] # number of fans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lenght of dataset is 5 - **5 samples in our dataset**. The shape of the dataset is **(5,3)**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the **first sample** and feed this to our neural network.<br>\n",
    "Our goal is to calculate the **weighted sum** across all input features.<br>\n",
    "Formally, we can write: `predictions = weight_1 * input_1 + weight_2 * input_2 + weight_3 * input_3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [toes[0], wlrec[0], nfans[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_sum(inputs, weights):\n",
    "    # first, we assert the input size is equal to weights length\n",
    "    # again, we assume the use of a single hidden dimension, so the hidden_dim = 1\n",
    "    assert(len(inputs) == len(weights))\n",
    "    pred = 0\n",
    "    # if the input size is equal to weght size, we can iterate over their size\n",
    "    for i in range(len(inputs)):\n",
    "        pred += (inputs[i]*weights[i])\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply neural net to calculate the total predictions (linear combination of all local pedictions)\n",
    "predictions =neural_network(inputs, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of network: 1.34\n"
     ]
    }
   ],
   "source": [
    "print('Output of network:', predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main takeaway**:<br>\n",
    "\n",
    "> 1. Neural networks combine multiple **local** predicctions in one as the linear combination of weights and corresponding input at the single timestamp.<br>\n",
    "Recall, we treat **weights as knowledge**, **input as information** and **output of weighted sum as predictions**. <br>\n",
    "So, the calculation of weighted sum once per instance.<br>\n",
    "\n",
    "> 2. In order to make accurate predictions, we need to combine multiple data inputs (features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Anytime you perform a mathematical operation between two vectors of equal length where\n",
    "you **pair up values according to their position in the vector** (again: position 0 with 0, 1 with 1,\n",
    "and so on), itâ€™s called an **elementwise operation**.<br> Thus elementwise addition sums two vectors,\n",
    "and elementwise multiplication multiplies two vectors.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([ 0, 1, 0, 1])\n",
    "b = np.array([ 1, 0, 1, 0])\n",
    "c = np.array([ 0, 1, 1, 0])\n",
    "d = np.array([.5, 0,.5, 0])\n",
    "e = np.array([ 0, 1,-1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intuition behind the dot product is just a weighted sum, when we perform **element-wise multiplication of vectors and sum up the element-wise results**.<br>\n",
    "As well, dot product gives as a notion of **similarity between two vectors** of equal size.<br>\n",
    "Let's calculate the dot products of the vectors above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot product of a and b: 0\n",
      "Dot product of b and c: 1\n",
      "Dot product of b and d: 1.0\n",
      "Dot product of c and c: 2\n",
      "Dot product of d and d: 0.5\n"
     ]
    }
   ],
   "source": [
    "print('Dot product of a and b:', a@b)\n",
    "print('Dot product of b and c:', b@c)\n",
    "print('Dot product of b and d:', b@d)\n",
    "print('Dot product of c and c:', c@c)\n",
    "print('Dot product of d and d:', d@d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First observation: vectors a and b have no overlapping weights, that's why their dot product (or similarity) is 0.<br>\n",
    "Second observation: vectors b and c have 2nd overlapping position, their similarity is 1. <br>\n",
    "Third observation: vectors c and e have positive similarity on 1st position, but the negative weight cancells it out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's demonstrate this property with logical `AND` operator.<br>\n",
    "Vectors a and b do not share the similarity between 0th elements. The `AND` operator returns 0 for them.<br>\n",
    "However, b and c have 2nd position similar and operator returns 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a[0] and b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(b[2] and c[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a[0] and b[0]) or (a[1] and b[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform **vectorized code** for our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(inputs, weights):\n",
    "    pred = np.dot(inputs, weights)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array([0.1, 0.2, 0.3]) # numpy weights for 3 features\n",
    "inputs = np.array([toes[0], wlrec[0], nfans[0]]) # numpy array of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_vectorized = neural_network(inputs, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized predictions: 1.34\n"
     ]
    }
   ],
   "source": [
    "print('Vectorized predictions:', pred_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions with single input and multiple outputs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks can make **multiple predictions** even with a single input.<br>\n",
    "In this case we talk about **multiple activations** or multiple hidden neurons.<br>\n",
    "In case of a single input, but multiple hidden neurons, we will have weights of shape `(1, hidden_dim)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose, we want to make **3 predictions** or create **3 hidden neurons**:\n",
    " - whether the  won or lost;\n",
    " - whethwer the players are happy or sad;\n",
    " - percentage of team players who are hurt.\n",
    " As an input we will use a single feature: `wlrec` (ratio of wins and losses) for one data sample (`m=1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(inputs, weights):\n",
    "    # perform element-wise multiplication\n",
    "    pred = ele_wise(inputs, weights)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ele_wise(inputs, weights):\n",
    "    # initiate the list of zeros, with lenght = hidden_dim = 3 (number of outputs)\n",
    "    output = [0,0,0] \n",
    "    # we make sure the weights dimension equals hidden_dim\n",
    "    assert (len(output) == len(weights))\n",
    "    for i in range(len(weights)):\n",
    "        # we have a single input, that will be multiplied by weight, that corresponds to each activation (each output)\n",
    "        output[i] = inputs * weights[i]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = wlrec[0]\n",
    "weights = np.array([0.3, 0.2, 0.9])\n",
    "output = neural_network(inputs, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.195, 0.13, 0.5850000000000001]\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the output above, the network performs output of `size = 3`, **multiplying a single input (for a single sample) by weight**, corresponding to each neuron (or output)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting with multiple inputs and outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to make **multiple predictions based on multiple inputs**.<br>\n",
    "\n",
    "As previously, we *connect each input node to each output node*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were given with weights matrix for 3 outputs (hidden_dim): hurt, win/loss, sad*.<br>\n",
    "The shape of weights matrix is (3x3), so the `(input_size, input_size)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array([ [0.1, 0.1, -0.3], # hurt?\n",
    "            [0.1, 0.2, 0.0], # win?\n",
    "            [0.0, 1.3, 0.1] ]) # sad? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "toes = [8.5, 9.5, 9.9, 9.0]\n",
    "wlrec = [0.65,0.8, 0.8, 0.9]\n",
    "nfans = [1.2, 1.3, 0.5, 1.0]\n",
    "\n",
    "inputs = np.array([toes[0], wlrec[0], nfans[0]]).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(inputs, weights):\n",
    "    output = vect_matmul(inputs, weights)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of `vect_matmul()` function is to **multiply each input datapoint from `inputs` list by corresponding weights**.<br>\n",
    "In fact, we will perform **vector-matrix multiplication** for inputs vector and matrix of weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the input: (1, 3)\n",
      "Shape of the weights: (3, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of the input:', inputs.shape)\n",
    "print('Shape of the weights:', weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape of the input is `(m,input_size)`. In outr case `m=1` and `input_size` = 3 <br>\n",
    "Shape of the weights is `(input_size, hidden_dim)`. <br>\n",
    "\n",
    "> Rows determine the `input_size`, or in other words **there are 3 weights coming to each output node (or hidden neuron)**. <br>For example, 3 weights [0.1, 0.2, 0.0] go to the \"win\" output node from 3 features of a single sample.<br>\n",
    "\n",
    "> In other words, we can think of **3 weights go from each feature (columns) to corresponding ouptut nodes**. <br>\n",
    "For example we have 3 weights, coming from `toes` feature [0.1, 0.1, 0.] to 3 corresponging output nodes.\n",
    "\n",
    "Thus, rows of weights matrix represent the number of input features and columns represent the output nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to **activate all `m` samples**, so the output will have shape of `(m, hiddem_size)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.5  0.65 1.2 ]]\n"
     ]
    }
   ],
   "source": [
    "print(inputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.1  0.1  0. ]\n",
      " [ 0.1  0.2  1.3]\n",
      " [-0.3  0.   0.1]]\n"
     ]
    }
   ],
   "source": [
    "print(weights.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To follow the logic above, we need to transpose the matrix of weights. <br>\n",
    "**Example**: for the first feature `toes` we have: 0.85 * 0.1, 0.85 * 0.1, 0.85 * 0.0. From a single feature we have 3 weights, corresponding to 3 different hidden neurons. Then, we need to sum 3 independent activations for `toes` to activations of rest of the features.<br>\n",
    "We can think about it as **3 independent dot products**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.555, 0.98 , 0.965]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how the output is calculated, using vectorization\n",
    "inputs @ weights.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining `vect_matmul` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose, we want to calculate **3 neurons**, hence `hidden_dim` = 3.<br>\n",
    "Using the weighted sum function `w_sum` we defined above, we need to calculate 3 outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the inputs vector without reshaping\n",
    "inputs = np.array([toes[0], wlrec[0], nfans[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_sum(a, b):\n",
    "    # start calculating predictions for a single neuron (single output)\n",
    "    # number of features must be equal to weights size\n",
    "    assert(len(a) == len(b)) \n",
    "    output = 0\n",
    "    for i in range(len(a)):\n",
    "        output += (a[i] *b [i])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " - vect - vector of inputs\n",
    " - matrix - matrix of weights\n",
    "\"\"\"\n",
    "def vect_mat_mul(vect,matrix):\n",
    "    # since we want to get 3 outputs, we need to initialiase 3 neurons of zeros\n",
    "    assert(len(vect) == len(matrix))\n",
    "    output = [0,0,0]\n",
    "    # iterate over the output neurons\n",
    "    for i in range(len(vect)):\n",
    "        # perform the weighted sum of input vector and corresponding matrix weights\n",
    "        # conceptually, we multiply each data input (each input feature) (information) by neurons weights (knowledge)\n",
    "        output[i] = w_sum(vect,matrix[i])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = neural_network(inputs, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21350000000000002, 0.08034999999999999, 0.227455]\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that 3 predictions are **completely separate from each other** (3 seprarate dot products). <br>\n",
    "Unlike the network with **multiple inputs and the single output**, we multiply the feature inputs with separate set of weights for each of 3 neurons.<br>\n",
    "We called these 3 outputs as **hurt** prediction, **win/loss** predictions, **sad** predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perdicting on predictions: Stacked NNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Networks' layers can be stacked and we can make predictions based on the **outputs of the hidden layer**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose, we want to include a hidden layer and make **predictions based on hidden layer outputs**.<br>\n",
    "Hidden neurons = 3 (`hidden_dim` = 3).<br>\n",
    "Output neurons = 3 (`output_dim` = 3).<br>\n",
    "\n",
    "In order to perform calculations and output 3 predictions for a single sample, we need to initialize **2 weights matrices** and perform **2 vector-matrix multiplications** using `vect_matmul`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.array([toes[0], wlrec[0], nfans[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, initiate weights, connecting inputs to hidden units (neurons)\n",
    "ih_wgt = np.array([[0.1, 0.2, -0.1], # hid[0]\n",
    "                   [-0.1,0.1, 0.9],   # hid[1]\n",
    "                   [0.1, 0.4, 0.1]]) # hid[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, we connect the output of hidden layer with output layer, producing 3 outputs\n",
    "hp_wgt = [ [0.3, 1.1, -0.3], # hurt?\n",
    " [0.1, 0.2, 0.0], # win?\n",
    " [0.0, 1.3, 0.1] ] # sad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatinate 2 weight matrices\n",
    "weights = [ih_wgt, hp_wgt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(inputs, weights):\n",
    "    hidden_out = vect_matmul(inputs, weights[0]) # vector-matrix multiplication for hidden layer\n",
    "    output = vect_mat_mul(hidden_out, weights[1]) # vector-matrix multiplication for output as \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = neural_network(inputs, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21350000000000002, 0.14500000000000002, 0.5065]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorized Numpy version for 1-hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just rewrite the function above in vectorized form.<br>\n",
    "An important thing to note here is that we need to **transpose the weight matrices** to make dot product follow the logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, initiate weights, connecting inputs to hidden units (neurons)\n",
    "ih_wgt = np.array([[0.1, 0.2, -0.1], # hid[0]\n",
    "                   [-0.1,0.1, 0.9],   # hid[1]\n",
    "                   [0.1, 0.4, 0.1]]).T # hid[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, we connect the output of hidden layer with output layer, producing 3 outputs\n",
    "hp_wgt = np.array([[0.3, 1.1, -0.3], # hurt?\n",
    "          [0.1, 0.2, 0.0], # win?\n",
    "          [0.0, 1.3, 0.1]]).T # sad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatinate 2 weight matrices\n",
    "weights = [ih_wgt, hp_wgt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(inputs, weights):\n",
    "    hidden_out = inputs @ weights[0]\n",
    "    output = hidden_out @ weights[1]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2135, 0.145 , 0.5065])"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network(inputs, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main takeaway**: it's always much efficient to use vectorization instead of for loops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canonical shapes in machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rule of thub is to follow some guidelines for input/output shapes:\n",
    " - input data has dimension `(m, input_size)`, where `m` - number of samples, `input_size` - number of features or dimensionality.\n",
    " - weight matrix has dimension `(input_size, hidden_dim)`, where `input_size` - dimensionality of input, `hidden_dim` - the size of hidden layer or number of neurons.\n",
    " - hidden output, that is the result of multiplication of input data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
